# The code below was generated by AI; see [X] in Use_of_AI.md.
version: "3.8"

services:
  inference-server:
    # For local development, you can build from the current folder:
    build: .
    # After you push to Docker Hub, switch to:
    # image: manas2006/project2:latest
    ports:
      - "8000:8000"
    environment:
      - MODEL_PATH=/code/results/best_model.h5
